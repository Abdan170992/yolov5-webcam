{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gwR_1EKWP7ho"},"source":["Define the webcam\n","\n"]},{"cell_type":"code","metadata":{"id":"Iq0QgCDJtOOg","executionInfo":{"status":"ok","timestamp":1618536148323,"user_tz":-420,"elapsed":2614,"user":{"displayName":"Abdan Syakura","photoUrl":"","userId":"05193487924094148247"}}},"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from google.colab.patches import cv2_imshow\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"hXzrSbITrHux","executionInfo":{"status":"ok","timestamp":1618536158344,"user_tz":-420,"elapsed":1713,"user":{"displayName":"Abdan Syakura","photoUrl":"","userId":"05193487924094148247"}}},"source":["def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"cG_uYjLRrcez","executionInfo":{"status":"ok","timestamp":1618536164180,"user_tz":-420,"elapsed":2406,"user":{"displayName":"Abdan Syakura","photoUrl":"","userId":"05193487924094148247"}}},"source":["def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","\n","  # get photo data\n","  data = eval_js('takePhoto({})'.format(quality))\n","  # get OpenCV format image\n","  img = js_to_image(data) \n","  \n","  # call our darknet helper on webcam image\n","  detections, width_ratio, height_ratio = darknet_helper(img, width, height)\n","\n","  # loop through detections and draw them on webcam image\n","  for label, confidence, bbox in detections:\n","    left, top, right, bottom = bbox2points(bbox)\n","    left, top, right, bottom = int(left * width_ratio), int(top * height_ratio), int(right * width_ratio), int(bottom * height_ratio)\n","    cv2.rectangle(img, (left, top), (right, bottom), class_colors[label], 2)\n","    cv2.putText(img, \"{} [{:.2f}]\".format(label, float(confidence)),\n","                      (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n","                      class_colors[label], 2)\n","  # save image\n","  cv2.imwrite(filename, img)\n","\n","  return filename"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxgW8JcFss3n"},"source":["'''try:\n","  filename = take_photo('photo.jpg')\n","  print('Saved to {}'.format(filename))\n","  \n","  # Show the image which was just taken.\n","  display(Image(filename))\n","except Exception as err:\n","  # Errors will be thrown if the user does not have a webcam or if they do not\n","  # grant the page permission to access it.\n","  print(str(err))'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScqYnwb3ri-O","executionInfo":{"status":"ok","timestamp":1618536173475,"user_tz":-420,"elapsed":2212,"user":{"displayName":"Abdan Syakura","photoUrl":"","userId":"05193487924094148247"}}},"source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","  \n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPwvC2G9rl2U"},"source":["'''# start streaming video from webcam for testing\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0 \n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    frame = js_to_image(js_reply[\"img\"])\n","\n","    # create transparent overlay for bounding box\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n44j_GenQA8j"},"source":["Clone and build yolov5"]},{"cell_type":"code","metadata":{"id":"WmyKd-s_dJnx"},"source":["!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","%pip install -qr requirements.txt  # install dependencies\n","\n","import torch\n","from IPython.display import Image, clear_output  # to display images\n","\n","clear_output()\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kW02XeUdRnr-"},"source":["Test image"]},{"cell_type":"code","metadata":{"id":"2O7NZAUxeI9Z"},"source":["!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images/\n","Image(filename='runs/detect/exp/zidane.jpg', width=600)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zjmrXRxcQQ4n"},"source":["Download a video for testing"]},{"cell_type":"code","metadata":{"id":"f-_VJHnMEuCN"},"source":["#!wget \"https://drive.google.com/uc?export=download&id=1hFDIiJbG_lnJq-hEMWNUb4dVPNUOQwZc\" -O \"test.mp4\"\n","#https://drive.google.com/file/d/1j3LaWiI2z0pIYCqJg_2SLXMrqpGZBGTr/view?usp=sharing\n","!wget \"https://drive.google.com/uc?export=download&id=1j3LaWiI2z0pIYCqJg_2SLXMrqpGZBGTr\" -O \"test.mp4\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EinKWvdhQTeN"},"source":["Test the video"]},{"cell_type":"code","metadata":{"id":"q-bxI7bH6Cak"},"source":["!python3 detect.py --weights yolov5s.pt --source test.mp4 --conf 0.25 --name test_result.mp4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLdzmTn_g1NG"},"source":["!pip install ffmpeg"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xgZ4Kk3fQZ0c"},"source":["Compress the result of the testing for displaying. Google Colab could not handle a large file"]},{"cell_type":"code","metadata":{"id":"URrW2Esrh4fv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618537649084,"user_tz":-420,"elapsed":2285,"user":{"displayName":"Abdan Syakura","photoUrl":"","userId":"05193487924094148247"}},"outputId":"f61b63c1-4507-49dd-c449-749c32371150"},"source":["# compress the video result\n","!ffmpeg -i runs/detect/test_result.mp4/test.mp4 -vcodec h264 -b:v 1000k -acodec mp2 output.mp4"],"execution_count":1,"outputs":[{"output_type":"stream","text":["ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","\u001b[1;31mruns/detect/test_result.mp4/test.mp4: No such file or directory\n","\u001b[0m"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8sYz5D_LQlQw"},"source":["Display the result of video testing"]},{"cell_type":"code","metadata":{"id":"mu3yYsS4WgzT"},"source":["#Display the video result after compressed\n","\n","import time\n","import glob\n","import torch\n","import os\n","\n","import argparse\n","from sys import platform\n","\n","from IPython.display import HTML\n","from base64 import b64encode\n","\n","# compress video\n","path_video = 'output.mp4'\n","\n","# Show video\n","mp4 = open(path_video,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=800 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NJbbyUrrQqFg"},"source":["Using webcam as the input to run the multiple object detection program. It is not recommeded because it is running very slow\n"]},{"cell_type":"code","metadata":{"id":"NvykOV7B25O6"},"source":["# multiple object detection with webcam using pretrained model (Not recommeded)\n","'''\n","import torch\n","from torchvision import transforms\n","import torch.backends.cudnn as cudnn\n","from numpy import random\n","\n","# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","bbox = ''\n","# Load the model and set the hyperparameters up\n","#model = torch.hub.load('ultralytics/yolov5', 'custom', path_or_model='yolov5s.pt')\n","#model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n","model = torch.hub.load('ultralytics/yolov5', 'custom', path_or_model='yolov5s.pt', force_reload=True, verbose = True)\n","cudnn.benchmark = True\n","#model.verbose = False\n","#model.autoshape()\n","model.conf = 0.25  # confidence threshold (0-1)\n","model.iou = 0.45  # NMS IoU threshold (0-1)\n","model.classes = None #[0, 15, 16]  # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n","\n","while True:\n","  js_reply = video_frame(label_html, bbox)\n","  if not js_reply:\n","    break\n","  \n","  # convert JS response to OpenCV Image\n","  frame = js_to_image(js_reply[\"img\"])\n","  #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","  #frame = cv2.flip(frame, 1)\n","  # create transparent overlay for bounding box\n","  bbox_array = np.zeros([480,640,4], dtype=np.uint8) \n","  \n","  result = model(frame)\n","  \n","  Class_name = result.pandas().xyxy[0].name\n","  Confidence = result.pandas().xyxy[0].confidence\n","  colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(Class_name))]\n","  Xmin = result.pandas().xyxy[0].xmin\n","  Ymin = result.pandas().xyxy[0].ymin\n","  Xmax = result.pandas().xyxy[0].xmax\n","  Ymax = result.pandas().xyxy[0].ymax\n","\n","  #print(result.pandas().xyxy[0])\n","  \n","  _, _, h, w = result.s\n","  img_height, img_width, _ = frame.shape\n","  \n","  width_ratio = img_width/w\n","  height_ratio = img_height/h\n","\n","  #names = model.module.names if hasattr(model, 'module') else model.names\n","  #colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))] \n","\n","  for i in range(0, len(Class_name)):\n","    xmin = int(Xmin[i] + 0.5)\n","    ymin = int(Ymin[i] + 0.5)\n","    xmax = int(Xmax[i] + 0.5)\n","    ymax = int(Ymax[i] + 0.5)\n","\n","    xmin = int(xmin * width_ratio)\n","    ymin = int(ymin * height_ratio)\n","    xmax = int(xmax * width_ratio)\n","    ymax = int(ymax * height_ratio)\n","\n","    bbox_array = cv2.rectangle(bbox_array, (xmin, ymin), (xmax, ymax), colors[i], 2)\n","    bbox_array = cv2.putText(bbox_array, Class_name[i],\n","                        (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n","                        colors[i], 2)\n","\n","  bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","  \n","  # convert overlay of bbox into bytes\n","  bbox_bytes = bbox_to_bytes(bbox_array)\n","  \n","  # update bbox so next frame gets new overlay\n","  bbox = bbox_bytes'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DFvplgv1RBpt"},"source":["USE THIS ONE TO RUN THE PROGRAM"]},{"cell_type":"code","metadata":{"id":"LQYj5SipRXkX"},"source":[" # Real multiple object detection with webcam using pretrained model with multi-threading\n","'''\n","The labelling is still not accurate, caused by canvas for labelling is shifted. Need to be fixed in javascript part.\n","\n","The hyperparameters are not optimal yet. Need to be tuned.\n","\n","This part is using multithreading in order run the detection in real-time  \n","'''\n","\n","import torch\n","from torchvision import transforms\n","import torch.backends.cudnn as cudnn\n","from numpy import random\n","import threading\n","import queue\n","\n","# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","bbox = ''\n","# Load the model and set the hyperparameters up\n","model = torch.hub.load('ultralytics/yolov5', 'custom', path_or_model='yolov5s.pt', force_reload=True, verbose = True)\n","cudnn.benchmark = True\n","model.conf = 0.25  # confidence threshold (0-1)\n","model.iou = 0.45  # NMS IoU threshold (0-1)\n","model.classes = None #[0, 15, 16]  # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n","\n","my_queue = queue.Queue()\n","\n","def storeInQueue(f):\n","  def wrapper(*args):\n","    my_queue.put(f(*args))\n","  return wrapper\n","\n","@storeInQueue\n","def detection(frame, bbox_array):\n","  result = model(frame)\n","  \n","  Class_name = result.pandas().xyxy[0].name\n","  Confidence = result.pandas().xyxy[0].confidence\n","  colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(Class_name))]\n","  Xmin = result.pandas().xyxy[0].xmin\n","  Ymin = result.pandas().xyxy[0].ymin\n","  Xmax = result.pandas().xyxy[0].xmax\n","  Ymax = result.pandas().xyxy[0].ymax\n","  \n","  _, _, h, w = result.s\n","  img_height, img_width, _ = frame.shape\n","  \n","  width_ratio = img_width/w\n","  height_ratio = img_height/h\n","\n","  for i in range(0, len(Class_name)):\n","    xmin = int(Xmin[i] + 0.5)\n","    ymin = int(Ymin[i] + 0.5)\n","    xmax = int(Xmax[i] + 0.5)\n","    ymax = int(Ymax[i] + 0.5)\n","\n","    xmin = int(xmin * width_ratio)\n","    ymin = int(ymin * height_ratio)\n","    xmax = int(xmax * width_ratio)\n","    ymax = int(ymax * height_ratio)\n","\n","    bbox_array = cv2.rectangle(bbox_array, (xmin, ymin), (xmax, ymax), colors[i], 2)\n","    bbox_array = cv2.putText(bbox_array, Class_name[i],\n","                        (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n","                        colors[i], 2)\n","  bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","  # convert overlay of bbox into bytes\n","  bbox_bytes = bbox_to_bytes(bbox_array)\n","  \n","  # update bbox so next frame gets new overlay\n","  # bbox = bbox_bytes\n","  return bbox_bytes\n","\n","while True:\n","  js_reply = video_frame(label_html, bbox)\n","  if not js_reply:\n","    break\n","  \n","  # convert JS response to OpenCV Image\n","  frame = js_to_image(js_reply[\"img\"])\n","\n","  # create transparent overlay for bounding box\n","  bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","  t1 = threading.Thread(target=detection, args=(frame, bbox_array))\n","  t1.start()\n","  #t1.join()\n","  my_data = my_queue.get()\n","  bbox = my_data\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cR3Nreo_gFTn"},"source":["OPTIONAL"]},{"cell_type":"code","metadata":{"id":"3UGvWpevda9J"},"source":["# Download COCO val2017\n","torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017val.zip', 'tmp.zip')\n","!unzip -q tmp.zip -d ../ && rm tmp.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RPMilAI0deg1"},"source":["# Run YOLOv5x on COCO val2017\n","!python test.py --weights yolov5x.pt --data coco.yaml --img 640 --iou 0.65"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dovb03TZdgMP"},"source":["# Download COCO test-dev2017\n","torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels.zip', 'tmp.zip')\n","!unzip -q tmp.zip -d ../ && rm tmp.zip # unzip labels\n","!f=\"test2017.zip\" && curl http://images.cocodataset.org/zips/$f -o $f && unzip -q $f && rm $f  # 7GB,  41k images\n","%mv ./test2017 ../coco/images  # move to /coco"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bymn4UiEdhpU"},"source":["# Run YOLOv5s on COCO test-dev2017 using --task test\n","!python test.py --weights yolov5s.pt --data coco.yaml --task test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AH8Rtc3TiF10"},"source":["# Download COCO128\n","torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n","!unzip -q tmp.zip -d ../ && rm tmp.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHanMJWZiNeJ"},"source":["# Tensorboard (optional)\n","%load_ext tensorboard\n","%tensorboard --logdir runs/train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kw_86UZdiXm5"},"source":["# Weights & Biases (optional)\n","%pip install -q wandb  \n","!wandb login  # use 'wandb disabled' or 'wandb enabled' to disable or enable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwdRTnT7jKFB"},"source":["# Train YOLOv5s on COCO128 for 3 epochs\n","!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --nosave --cache"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DGKlAq5kjeva"},"source":["Image(filename='runs/train/exp/train_batch0.jpg', width=800)  # train batch 0 mosaics and labels\n","Image(filename='runs/train/exp/test_batch0_labels.jpg', width=800)  # test batch 0 labels\n","Image(filename='runs/train/exp/test_batch0_pred.jpg', width=800)  # test batch 0 predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4OS4a2hcjlbP"},"source":["from utils.plots import plot_results \n","plot_results(save_dir='runs/train/exp')  # plot all results*.txt as results.png\n","Image(filename='runs/train/exp/results.png', width=800)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejYw-nkTj-gd"},"source":["# Re-clone repo\n","%cd ..\n","%rm -rf yolov5 && git clone https://github.com/ultralytics/yolov5\n","%cd yolov5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dzI6X5OnkDYO"},"source":["# Reproduce\n","for x in 'yolov5s', 'yolov5m', 'yolov5l', 'yolov5x':\n","  !python test.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.25 --iou 0.45  # speed\n","  !python test.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.001 --iou 0.65  # mAP"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyOGjBrgpqr0"},"source":["# PyTorch Hub\n","import torch\n","\n","# Model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n","\n","# Images\n","dir = 'https://github.com/ultralytics/yolov5/raw/master/data/images/'\n","imgs = [dir + f for f in ('zidane.jpg', 'bus.jpg')]  # batch of images\n","\n","# Inference\n","results = model(imgs)\n","#results.print()  # or .show(), .save()\n","results.show()"],"execution_count":null,"outputs":[]}]}